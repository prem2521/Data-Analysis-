# -*- coding: utf-8 -*-
"""EDA Assesment.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1r8Mk1XZfP55131ia5RJkJhzjg-MMNU-y

## **Assignment 1: Data Cleaning and Exploration using Python**

# Importing libraries
"""

import pandas as pd
import numpy as np

"""The lines import pandas as pd and import numpy as np are used to include two important libraries in Python:

1. Import pandas as pd:

This line imports the pandas library, which is a powerful tool for data manipulation and analysis.
By using pd, you can easily access all the functions and features of pandas. For example, you can create data tables (DataFrames), perform data analysis, and clean or transform data.

2. Import numpy as np:

This line imports the NumPy library, which is used for numerical computing in Python.
With np, you can work with arrays and perform mathematical operations efficiently. NumPy is especially useful for handling large datasets and performing complex calculations.
In simple words, these lines allow you to use pandas for working with data tables and NumPy for handling numbers and mathematical functions in your Python code.

**Here is the dataset that we will be using:**

 [Link](https://drive.google.com/file/d/1Nn-jKdZCIgQrOOSztGRYHm-jwo4wluAJ/view)

# Load the dataset
"""

filepath="/content/AB_NYC_2019 (1).csv"
df=pd.read_csv(filepath)
df

"""This code does two things:

1.filepath="/content/AB_NYC_2019.csv":

It defines a variable filepath that holds the location of the CSV file (AB_NYC_2019.csv) on your system. In this case, it’s in the /content/ directory (probably in Google Colab or a similar environment).
2.df = pd.read_csv(filepath):

This reads the CSV file from the specified filepath using pandas' read_csv() function and loads the data into a pandas DataFrame called df.
A DataFrame (df) is like a table of data, where rows are records (e.g., listings) and columns are different attributes (e.g., price, neighborhood, etc.).
In simple terms, this code loads the data from a CSV file into a table (df) that you can now analyze and manipulate in Python.

# Data Preparation in Python
"""

df.head()

"""df.head() is a command that displays the first few rows (usually the first 5) of the DataFrame df.

In simple words:
It helps you quickly see a sample of your data to understand its structure, including the column names and the type of values in each column.
This is useful for getting a quick overview of what your dataset looks like without printing the entire DataFrame.
So, when you use df.head(), you get a sneak peek at the beginning of your data!
"""

df.tail()

"""df.tail() shows the last 5 rows of the DataFrame df by default.

Breakdown:
df.tail(): This retrieves the last 5 rows of data.
df.tail(n): You can also specify a number n to see the last n rows.
In simple words, df.tail() lets you see the last few entries of your dataset, which is helpful when you want to quickly check the end of your data.
"""

df.info()

"""df.info() gives a summary of the DataFrame df, showing important information about the structure of your data.

Breakdown:
Column names: Lists all the columns in the DataFrame.
Data types: Shows the type of data in each column (e.g., integer, float, object for strings).
Non-null values: Displays how many non-missing (non-null) values are in each column.
Memory usage: Tells you how much memory the DataFrame is using.
In simple words, df.info() provides an overview of your data, including column names, data types, how many missing values there are, and how much space your data takes up.
"""

df.describe()

"""df.describe() gives a quick summary of the main statistics for the numerical columns in the DataFrame df.

Breakdown:
For numeric columns, it shows:
Count: The number of non-missing values.
Mean: The average value.
Std: The standard deviation (how spread out the numbers are).
Min: The smallest value.
25%, 50% (median), 75%: Percentiles, showing where the data lies.
Max: The largest value.
In simple words, df.describe() provides a snapshot of key statistics (like average, min, max) for the numerical data in your dataset. It's a useful tool to quickly understand your data.

# Handle Missing Values:
"""

df.isnull().sum()

"""
df.isnull().sum() is used to check how many missing (null) values there are in each column of the DataFrame df.

Breakdown:
df.isnull(): This creates a DataFrame of the same shape where each cell is either True (if the value is missing) or False (if it's not missing).
.sum(): This sums up the True values for each column (since True is treated as 1 and False as 0), giving the total number of missing values in each column.
In simple words, this command counts how many missing values are in each column of your dataset."""

df.mean(numeric_only=True)

"""df.mean(numeric_only=True) calculates the average (mean) of only the numeric columns in the DataFrame df.

Breakdown:
df.mean(): By default, this calculates the mean for all columns, but non-numeric columns (like strings) will cause issues.
numeric_only=True: This option ensures that only the numeric columns (like integers and floats) are considered when calculating the mean, and any non-numeric columns are ignored.
In simple terms, this command finds the average value for all the numerical columns in your data, ignoring any text or non-numeric columns.
"""



#We know that reviews_per_month column have many null values, we will replace it with '0'
df["reviews_per_month"].fillna(0,inplace=True)

#And name and host_name also have some empty indexes, replace it with 'Unknown' and 'no_name' resp.
df['host_name'].fillna('no_name',inplace=True)
df['name'].fillna('Unknown',inplace=True)

"""# Remove Duplicates:"""

df.duplicated().sum()
df.drop_duplicates(inplace=True)
duplicates_after = df.duplicated().sum()

"""1.Check for duplicates:
auto_df.duplicated().sum() checks for any duplicate rows in the dataset and counts them.

2.Drop duplicates:
auto_df.drop_duplicates(inplace=True) removes any duplicate rows from the dataset.
inplace=True modifies the DataFrame directly.

3.Verify removal:
After removing duplicates, the code checks again to ensure there are no more duplicates left.
This ensures your dataset is clean and free of duplicate rows.
"""

df.isnull().sum()

"""# Convert Data Types:"""

# 1: Convert 'last_review' column to datetime format
df['last_review'] = pd.to_datetime(df['last_review'], errors='coerce')
#df[['last_review']] = df [['last_review']].astype('datetime64[ns]')
# 2: Ensure 'price' is in numerical format
df['price'] = pd.to_numeric(df['price'], errors='coerce')
# 3: Verify data type conversions
df.dtypes

"""1.Convert last_review to datetime:
pd.to_datetime(auto_df['last_review'], errors='coerce') converts the last_review column to a datetime format. If any values cannot be converted, they will be replaced with NaT (Not a Time).

2.Ensure price is numeric:
pd.to_numeric(auto_df['price'], errors='coerce') ensures that the price column is numeric. Any invalid entries (like strings or invalid numbers) are converted to NaN.

3.Verify conversions:
auto_df.dtypes displays the data types of all columns, allowing you to check if the conversions were successful.
"""

# droping unnecessary columns
# df.drop(['id','last_review'], axis=1, inplace=True)

# Optional - Check if any values are NaN after conversion
print(df['price'].isnull().sum())
print(df['last_review'].isnull().sum())

"""Optional Check for NaN:
After conversion, it checks if any values in price or last_review became missing (NaN or NaT) due to conversion issues.
This ensures that the last_review column is in the correct datetime format, and the price column is properly formatted as a numeric type.

# Key Metrics Extraction:
"""

# 1: Total Listings
df.shape[0]  # The total number of rows

"""Total Listings:

df.shape[0] gives the total number of rows in the dataset, representing the total number of listings.
"""

# 2: Average Price per Listing
df['price'].mean()

"""Average Price per Listing:

auto_df['price'].mean() computes the average price across all listings.
"""

# 3: Top 5 Neighborhoods by Listings
# Assuming 'neighborhood' is the column representing the neighborhoods
df['neighbourhood_group'].value_counts().head(5)

"""Top 5 Neighborhoods by Listings:

auto_df['neighbourhood_group'].value_counts().head(5) counts the number of listings per neighborhood and retrieves the top 5.
"""

# 4: Room Type Distribution
# Assuming 'room_type' is the column representing different room types
room_type_distribution = df['room_type'].value_counts(normalize=True) * 100
room_type_distribution

"""Room Type Distribution:

auto_df['room_type'].value_counts(normalize=True) * 100 calculates the percentage distribution of different room types.
"""

# 5: Correlation Analysis between Price and Availability_365
# Assuming 'availability_365' is the column representing availability in days
correlation = df['price'].corr(df['availability_365'])
correlation

"""Correlation Analysis (Price vs Availability):

auto_df['price'].corr(auto_df['availability_365']) computes the Pearson correlation between price and availability_365, indicating if there’s any linear relationship between these two variables.

# **Assignment 2: Descriptive Statistics and Basic Data Visualization**

# Importing libraries
"""

import matplotlib.pyplot as plt
import seaborn as sns

"""1. The line import matplotlib.pyplot as plt is used to include the Matplotlib library in Python, specifically the pyplot module, which is commonly used for creating visualizations.

Breakdown:
import matplotlib.pyplot: This imports the pyplot module, which provides a collection of functions for making plots and charts.
as plt: This gives a shorthand name (plt) to the pyplot module, making it easier to use in your code.
In simple words, this line allows you to create various types of graphs and charts (like line plots, bar charts, and scatter plots) to help visualize your data. By using plt, you can easily call plotting functions with less typing.

2.
The line import seaborn as sns is used to include the Seaborn library in Python, which is built on top of Matplotlib.

Breakdown:
import seaborn: This imports the Seaborn library, which is designed for making statistical graphics.
as sns: This gives a shorthand name (sns) to the Seaborn library, making it easier to reference in your code.
In simple words, this line allows you to create beautiful and informative visualizations (like heatmaps, scatter plots, and bar charts) for your data analysis. By using sns, you can easily generate attractive plots with less code than using Matplotlib alone.

# Descriptive Statistics

***Calculate Mean,Median & Mode***
"""

# 1: Calculate mean, median, and mode for 'price' and 'availability_365'
df['price'].mean()

df['price'].median()

df['price'].mode()[0]  # Taking the first mode if there are multiple

mean_availability = df['availability_365'].mean()
median_availability = df['availability_365'].median()
mode_availability = df['availability_365'].mode()[0]  # Taking the first mode if there are multiple
print(mean_availability)
print(median_availability)
print(mode_availability)

"""Mean, Median, and Mode:

1.Mean: Average value calculated using .mean().

2.Median: The middle value when data is sorted, calculated using .median().

3.Mode: The most frequently occurring value, found using .mode(). The [0] ensures you get the first mode in case there are multiple.
"""

# 2: Variance and Standard Deviation for 'number_of_reviews'
variance_reviews =  df['number_of_reviews'].var()
std_dev_reviews =  df['number_of_reviews'].std()
print(variance_reviews)
print(std_dev_reviews)

"""Variance and Standard Deviation:

Variance: A measure of how much the values in number_of_reviews vary from the mean, calculated using .var().
Standard Deviation: The square root of the variance, indicating how spread out the values are, calculated using .std().
"""

# 3: Identify the top 10 hosts by the number of listings
# Assuming 'host_id' is the column representing hosts
top_10_hosts = df['host_id'].value_counts().head(10)
top_10_hosts

"""Top 10 Hosts by Number of Listings:

Uses value_counts() on the host_id column to count the number of listings for each host, and .head(10) retrieves the top 10 hosts with the most listings.

# Data Visualization

# 1: Bar Chart
"""

import matplotlib.pyplot as plt
import seaborn as sns

# Set the style for the plots
sns.set(style="whitegrid")

# 1: Bar Chart - Distribution of Airbnb listings across different neighborhood groups
plt.figure(figsize=(12, 6))
sns.countplot(data= df, x='neighbourhood_group', order= df['neighbourhood_group'].value_counts().index, palette='viridis')
plt.title('Distribution of Airbnb Listings Across neighbourhood_group')
plt.xlabel('neighbourhood_group')
plt.ylabel('Number of Listings')
plt.xticks(rotation=0)
plt.show()

"""🔸**Bar Chart**:

Distribution of Airbnb Listings: This chart shows how many listings there are in each neighborhood. It helps identify which neighborhoods are more popular

# 2: Scatter Plot
"""

import matplotlib.pyplot as plt
import seaborn as sns

# Set the style for the plots
sns.set(style="whitegrid")

# 2: Scatter Plot - Relationship between price and availability_365
plt.figure(figsize=(10, 6))
sns.scatterplot(data=df, x='availability_365', y='price', alpha=0.6, color='blue')
plt.title('Relationship Between Price and Availability (365 days)')
plt.xlabel('Availability (365 days)')
plt.ylabel('Price')
plt.show()

"""Scatter Plot:

Relationship Between Price and Availability: This plot visualizes the relationship between the price of listings and how available they are throughout the year. It helps to see if there's a trend or pattern.

# 3: Line Plot
"""

import pandas as pd
import matplotlib.pyplot as plt


# Convert the review date column to datetime
df['last_review'] = pd.to_datetime(df['last_review'])  # Adjust the column name as necessary

# Resample data to get the number of reviews per time period (e.g., daily or monthly)
reviews_over_time = df.resample('M', on='last_review').size()  # Use 'D' for daily or 'M' for monthly

# Create the line plot
plt.figure(figsize=(12, 6))
plt.plot(reviews_over_time.index, reviews_over_time.values, marker='o', linestyle='-')
plt.title('Number of Reviews Over Time')
plt.xlabel('Date')
plt.ylabel('Number of Reviews')
plt.xticks(rotation=45)
plt.grid()
plt.tight_layout()
plt.show()

"""Line Plot:

Number of Reviews Over Time: This time series chart shows how the total number of reviews has changed over time. It provides insights into trends in user engagement.

# 4: Pie Chart
"""

import matplotlib.pyplot as plt
import seaborn as sns

# Set the style for the plots
sns.set(style="whitegrid")

# 4: Pie Chart - Proportion of room types across the city
plt.figure(figsize=(8, 8))
room_type_counts = df['room_type'].value_counts()
plt.pie(room_type_counts, labels=room_type_counts.index, autopct='%1.1f%%', startangle=90, colors=sns.color_palette('pastel'))
plt.title('Proportion of Room Types Across the City')
plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.
plt.show()

"""**🔸Pie Chart:**

Proportion of Room Types: This pie chart illustrates the distribution of different room types (e.g., entire home, private room) in the city. It helps to see what types of accommodations are most common.

# 5: Heatmap
"""

import matplotlib.pyplot as plt
import seaborn as sns

# Set the style for the plots
sns.set(style="whitegrid")

# 5: Heatmap - Correlation heatmap for key variables
plt.figure(figsize=(10, 8))
correlation_matrix = df[['price', 'number_of_reviews', 'availability_365']].corr()
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=".2f", square=True, cbar_kws={"shrink": .8})
plt.title('Correlation Heatmap')
plt.show()

"""**🔸Heatmap:**

Correlation Heatmap: This heatmap shows the correlation between key variables like price, number of reviews, and availability. It helps to identify any strong relationships between these variables.

# 6: Count plot
"""

import matplotlib.pyplot as plt
import seaborn as sns

# Set the style for the plots
sns.set(style="whitegrid")

plt.figure(figsize=(9, 8))
sns.countplot(x='neighbourhood_group', data=df,hue='room_type', palette='viridis')
plt.title('Availability by Neighbourhood Group')
plt.xlabel('Neighbourhood Group')
plt.ylabel('Count')
plt.show()

"""# 7: Bar Charts

***1. Distribution of Price according to Room type***
"""

import matplotlib.pyplot as plt
import seaborn as sns

# Set the style for the plots
sns.set(style="whitegrid")

plt.figure(figsize=(10, 6))
color =['purple','yellow','green']


# Count listings b{
x= df['room_type'].value_counts()

plt.bar(x.index, x.values,color=color,)

plt.xlabel('Room Type')
plt.ylabel('Price')
plt.title('Distribution of Price according to Room type', fontsize=10)
plt.xticks(rotation=0)
plt.show()

""" ***🔸 Where is the most expensive area Price Difference
 Availability according to different room_type in different areas most popular area.***
"""

import matplotlib.pyplot as plt
import seaborn as sns

# Set the style for the plots
sns.set(style="whitegrid")

g = sns.catplot(x='neighbourhood_group',y='availability_365',kind='box',hue='room_type',data=df,palette='pastel')
# Access the underlying figure of the FacetGrid using g.fig
g.fig.suptitle('Where is the most popular area?',fontsize=15,y=1.05)
plt.show() # Add this line to display the plot if you are not using a Jupyter Notebook or similar

"""***🔸 Where is the most expensive area Price Difference***"""

import matplotlib.pyplot as plt
import seaborn as sns

# Set the style for the plots
sns.set(style="whitegrid")

# Price according to different room_type in different areas
fig2 = sns.catplot(x='neighbourhood_group',y='price',data=df,kind='bar',hue='room_type',palette='pastel')
fig2.fig.suptitle('Where is the most expensive area?',fontsize=15,y=1.05)

"""# 8: Pie Chart"""

import matplotlib.pyplot as plt
import seaborn as sns

# Set the style for the plots
sns.set(style="whitegrid")

reviews_by_neighbourhood = df.groupby('neighbourhood_group')['number_of_reviews'].sum()
plt.figure(figsize=(8, 6))
plt.pie(reviews_by_neighbourhood, labels=reviews_by_neighbourhood.index, autopct='%1.1f%%', colors=sns.color_palette('pastel'))
plt.title('Number of Reviews by Neighbourhood Group')
plt.axis('equal')  # Equal aspect ratio ensures that the pie is drawn as a circle.
plt.show()